{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks (Purchase prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def readGz(f):\n",
    "  for l in gzip.open(f):\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=list(readGz(\"assignment1/train.json.gz\"))\n",
    "train_data = data[:100000]\n",
    "valid_data = data[100000:200000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Although we have built a validation set, it only consists of positive samples. For this task we also need examples of user/item pairs that weren't purchased. Build such a set by randomly sampling users and items until you have 100,000 non-purchased user/item pairs. This random sample combined with your 100,000 validation reviews now corresponds to the complete validation set for the purchase prediction task. Evaluate the performance (accuracy) of the baseline model on the validation set you have built (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item = defaultdict(list)\n",
    "users = set()\n",
    "items =set()\n",
    "for l in data:\n",
    "    user,item = l['reviewerID'],l['itemID']\n",
    "    users.add(user)\n",
    "    items.add(item)\n",
    "    user_item[user].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_pair = []\n",
    "users = list(users)\n",
    "items = list(items)\n",
    "count = 0\n",
    "while count < 100000:\n",
    "    userrandom = random.choice(users)\n",
    "    itemrandom = random.choice(items)\n",
    "    pair = ((userrandom,itemrandom))\n",
    "    if itemrandom in user_item[userrandom]:\n",
    "            continue\n",
    "    else:\n",
    "        negative_pair.append(pair)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_valid = [x['reviewerID'] for x in valid_data]\n",
    "item_valid = [x['itemID'] for x in valid_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pair = list(zip(user_valid,item_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_pair = positive_pair + negative_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "businessCount = defaultdict(int)\n",
    "totalPurchases = 0\n",
    "\n",
    "for l in train_data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  businessCount[business] += 1\n",
    "  totalPurchases += 1\n",
    "\n",
    "mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "  count += ic\n",
    "  return1.add(i)\n",
    "  if count > totalPurchases/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for l in whole_pair:\n",
    "    if l[1] in return1:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "true = []\n",
    "for i in range(100000):\n",
    "    true.append(1)\n",
    "for i in range(100000):\n",
    "    true.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = []\n",
    "for i in range(len(pred)):\n",
    "    if pred[i] == true[i]:\n",
    "        g.append(1)\n",
    "    else:\n",
    "        g.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.629035\n"
     ]
    }
   ],
   "source": [
    "accuracy = sum(g)/len(g)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The existing 'purchase prediction' baseline just returns True if the item in question is 'popular', using a threshold of the 50th percentile of popularity (totalPurchases/2). Assuming that the `non-purchased' test examples are a random sample of user-purchase pairs, is this particular threshold value the best? If not, see if you can find a better one (and report its performance), or if so, explain why it is the best (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testthreshold(a):\n",
    "    businessCount = defaultdict(int)\n",
    "    totalPurchases = 0\n",
    "\n",
    "    for l in train_data:\n",
    "      user,business = l['reviewerID'],l['itemID']\n",
    "      businessCount[business] += 1\n",
    "      totalPurchases += 1\n",
    "\n",
    "    mostPopular = [(businessCount[x], x) for x in businessCount]\n",
    "    mostPopular.sort()\n",
    "    mostPopular.reverse()\n",
    "\n",
    "    return1 = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "      count += ic\n",
    "      return1.add(i)\n",
    "      if count > totalPurchases*a/100: break\n",
    "    \n",
    "    pred = []\n",
    "    for l in whole_pair:\n",
    "        if l[1] in return1:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(0)\n",
    "    \n",
    "    g = []\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == true[i]:\n",
    "            g.append(1)\n",
    "        else:\n",
    "            g.append(0)\n",
    "    accuracy = sum(g)/len(g)\n",
    "    return(a, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracylist = []\n",
    "import numpy as np\n",
    "for i in np.arange(1, 101, 1):\n",
    "    accuracylist.append(testthreshold(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = []\n",
    "for l in accuracylist:\n",
    "    correct.append(l[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct.index(max(correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 0.62949)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracylist[52]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### When the threshold is 53rd percentile of popularity, the accuracy is highest which is 0.62963."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Users may tend to repeatedly purchase items of the same type. Build a baseline that returns 'True' if a user has purchased an item of the same category before (at least one category in common), or zero otherwise (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_category = defaultdict(list)\n",
    "business_category = defaultdict(list)\n",
    "users = set()\n",
    "businesses = set()\n",
    "for l in train_data:\n",
    "    user,business,category= l['reviewerID'],l['itemID'],l['categories']\n",
    "    users.add(user)\n",
    "    businesses.add(business)\n",
    "    user_category[user].append(category)\n",
    "    business_category[business].append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in users:\n",
    "    y = []\n",
    "    for j in user_category[i]:\n",
    "        for h in j:\n",
    "            y.append(tuple(h))\n",
    "    user_category[i] = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in businesses:\n",
    "    y = []\n",
    "    for j in business_category[i]:\n",
    "        for h in j:\n",
    "            y.append(tuple(h))\n",
    "    business_category[i] = set(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_f = []\n",
    "for user,business in whole_pair:\n",
    "    a = user_category[user]\n",
    "    b = business_category[business]\n",
    "    if any (i in a for i in b):\n",
    "        predict_f.append(1)\n",
    "    else:\n",
    "        predict_f.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy is 0.59297\n"
     ]
    }
   ],
   "source": [
    "h = []\n",
    "for i in range(len(predict_f)):\n",
    "    if predict_f[i] == true[i]:\n",
    "        h.append(1)\n",
    "    else:\n",
    "        h.append(0)\n",
    "print(\"validation accuracy is \" + str(sum(h)/len(h)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. To run our model on the test set, we'll have to use the files `pairs Purchase.txt' to find the review- erID/itemID pairs about which we have to make predictions. Using that data, run the above model and upload your solution to Kaggle. Tell us your Kaggle user name (1 mark). If you've already uploaded a better solution to Kaggle, that's fine too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"assignment1/predictions_Purchase.csv\", 'w')\n",
    "for l in open(\"assignment1/pairs_Purchase.txt\"):\n",
    "  if l.startswith(\"reviewerID\"):\n",
    "    #header\n",
    "    predictions.write(l)\n",
    "    continue\n",
    "  u,i = l.strip().split('-')\n",
    "  if any (i in user_category[u] for i in business_category[i]):\n",
    "    predictions.write(u + '-' + i + \",1\\n\")\n",
    "  else:\n",
    "    predictions.write(u + '-' + i + \",0\\n\")\n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Kaggle username: Sihao Gu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks (Rating prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's start by building our training/validation sets much as we did for the first task. This time building a validation set is more straightforward, you can simply use half of the data for validation, and do not need to randomly sample non-purchased users/items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What is the performance of a trivial predictor rating(user, item) = alpha on the validation set, and what is the value of alpha (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha is 4.232\n"
     ]
    }
   ],
   "source": [
    "allRatings = []\n",
    "for l in train_data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  allRatings.append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "\n",
    "print('alpha is ' + str(globalAverage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 1.222481119999121\n"
     ]
    }
   ],
   "source": [
    "MSE = 0\n",
    "for l in valid_data:\n",
    "    MSE += (l['rating'] - globalAverage) ** 2\n",
    "\n",
    "MSE = MSE/len(train_data)\n",
    "\n",
    "print('MSE is ' + str(MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Fit a predictor of the form rating(user, item) = alpha + Beta(user) + Beta(item); by fitting the mean and the two bias terms as described in the lecture notes. Use a regularization parameter of lambda = 1. Report the MSE on the validation set (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate initial alpha, Beta(user), Beta(item)\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "businessRatings = defaultdict(list)\n",
    "for l in train_data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  allRatings.append(l['rating'])\n",
    "  userRatings[user].append(l['rating'])\n",
    "  businessRatings[business].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "businessAverage = {}\n",
    "for u in userRatings:\n",
    "  userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "for u in businessRatings:\n",
    "  businessAverage[u] = sum(businessRatings[u]) / len(businessRatings[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate(globalAverage, userAverage, businessAverage, lam = 1, \\\n",
    "            threshold = 0.00001):\n",
    "    switch = 0\n",
    "    prev_globalAverage = globalAverage\n",
    "    prev_userAverage = userAverage\n",
    "    prev_businessAverage = businessAverage\n",
    "    while switch == 0:\n",
    "        globalAverage = 0\n",
    "        for l in train_data:\n",
    "            user,business = l['reviewerID'],l['itemID']\n",
    "            globalAverage += (l[\"rating\"] - prev_userAverage[user] - \\\n",
    "                              prev_businessAverage[business])\n",
    "        globalAverage /= len(train_data)\n",
    "        \n",
    "        nbusiness = defaultdict(int)\n",
    "        for user in userAverage:\n",
    "            userAverage[user] = 0\n",
    "        for l in train_data:\n",
    "            user,business = l['reviewerID'],l['itemID']\n",
    "            nbusiness[user] += 1\n",
    "            userAverage[user] += (l[\"rating\"] - globalAverage - \\\n",
    "                                  prev_businessAverage[business])\n",
    "        for user in userAverage:\n",
    "            userAverage[user] /= (lam + nbusiness[user])\n",
    "        \n",
    "        difference_user = 0\n",
    "        for i in userAverage:\n",
    "            difference_user += abs(userAverage[i] - prev_userAverage[i])\n",
    "            \n",
    "        nuser = defaultdict(int)\n",
    "        for business in businessAverage:\n",
    "            businessAverage[business] = 0\n",
    "        for l in train_data:\n",
    "            user,business = l['reviewerID'],l['itemID']\n",
    "            nuser[business] += 1\n",
    "            businessAverage[business] += (l[\"rating\"] - globalAverage - \\\n",
    "                                          userAverage[user])\n",
    "        for business in businessAverage:\n",
    "            businessAverage[business] /= (lam + nuser[business])\n",
    "        \n",
    "        difference_bus = 0\n",
    "        for i in businessAverage:\n",
    "            difference_bus += abs(businessAverage[i] - prev_businessAverage[i])        \n",
    "        \n",
    "        if abs(globalAverage - prev_globalAverage) < threshold and \\\n",
    "        difference_user < threshold and \\\n",
    "        difference_bus < threshold:\n",
    "            switch = 1\n",
    "        else:\n",
    "            prev_globalAverage = globalAverage\n",
    "            prev_userAverage = userAverage\n",
    "            prev_businessAverage = businessAverage\n",
    "    return globalAverage, userAverage, businessAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE\n",
    "def MSE(globalAverage_update, userAverage_update, businessAverage_update):\n",
    "    mse = 0.0\n",
    "    userlist = []\n",
    "    businesslist = []\n",
    "    for i in userAverage_update:\n",
    "        userlist.append(i)\n",
    "    for j in businessAverage_update:\n",
    "        businesslist.append(j)\n",
    "    for l in valid_data:\n",
    "        user,business = l['reviewerID'],l['itemID']\n",
    "        if (user in userlist) & (business in businesslist):\n",
    "            mse += (l[\"rating\"]-globalAverage_update- \\\n",
    "                    userAverage_update[user]-businessAverage_update[business])**2\n",
    "        elif (user in userlist) & (business not in businesslist):\n",
    "            mse += (l[\"rating\"]-globalAverage_update-userAverage_update[user])**2\n",
    "        elif (user not in userlist) & (business in businesslist):\n",
    "            mse += (l[\"rating\"]-globalAverage_update-\\\n",
    "                    businessAverage_update[business])**2\n",
    "        else:\n",
    "            mse += (l[\"rating\"]-globalAverage_update)**2\n",
    "    mse /= 100000\n",
    "    print(\"MSE on validation data is \" + str(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalAverage_update, userAverage_update, businessAverage_update = iterate(\\\n",
    "            globalAverage,userAverage, businessAverage, lam = 1, threshold = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation data is 1.281118659105882\n"
     ]
    }
   ],
   "source": [
    "MSE(globalAverage_update,userAverage_update, businessAverage_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Report the user and item IDs that have the largest and smallest values of beta (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('U204516481', -2.5517066060072136)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smallest beta in User\n",
    "sorted(userAverage_update.items(), key = lambda item:item[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('U495776285', 1.486748655993029)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest beta in User\n",
    "sorted(userAverage_update.items(), key = lambda item:item[1])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I511389419', -2.575677187832548)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smallest beta in itemIDs\n",
    "sorted(businessAverage_update.items(), key = lambda item:item[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('I809804570', 1.2700396852824163)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# largest beta in itemIDs\n",
    "sorted(businessAverage_update.items(), key = lambda item:item[1])[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Find a better value of lambda using your validation set. Report the value you chose, its MSE, and upload your solution to Kaggle by running it on the test data (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam= 2.5\n",
      "MSE on validation data is 1.170350602374201\n",
      "lam= 5\n",
      "MSE on validation data is 1.139895608962076\n",
      "lam= 7.5\n",
      "MSE on validation data is 1.13809132350018\n",
      "lam= 10\n",
      "MSE on validation data is 1.1416031165965732\n"
     ]
    }
   ],
   "source": [
    "for lam in [2.5,5,7.5,10]:\n",
    "    globalAverage_update, userAverage_update, businessAverage_update = iterate(\\\n",
    "        globalAverage, userAverage, businessAverage, lam = lam, threshold = 0.00001)\n",
    "    print('lam= ' + str(lam))\n",
    "    MSE(globalAverage_update, userAverage_update, businessAverage_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam= 5.5\n",
      "MSE on validation data is 1.1386055295339117\n",
      "lam= 6\n",
      "MSE on validation data is 1.137923962774243\n",
      "lam= 6.5\n",
      "MSE on validation data is 1.1376840308091374\n",
      "lam= 7\n",
      "MSE on validation data is 1.137768041725769\n"
     ]
    }
   ],
   "source": [
    "for lam in [5.5,6,6.5,7]:\n",
    "    globalAverage_update, userAverage_update, businessAverage_update = iterate(\\\n",
    "        globalAverage, userAverage, businessAverage, lam = lam, threshold = 0.00001)\n",
    "    print('lam= ' + str(lam))\n",
    "    MSE(globalAverage_update, userAverage_update, businessAverage_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lam= 6.6\n",
      "MSE on validation data is 1.1376780068768086\n",
      "lam= 6.7\n",
      "MSE on validation data is 1.1376850951675586\n",
      "lam= 6.8\n",
      "MSE on validation data is 1.1377016238720616\n",
      "lam= 6.9\n",
      "MSE on validation data is 1.1377306752091179\n"
     ]
    }
   ],
   "source": [
    "for lam in [6.6,6.7,6.8,6.9]:\n",
    "    globalAverage_update, userAverage_update, businessAverage_update = iterate(\\\n",
    "        globalAverage, userAverage, businessAverage, lam = lam, threshold = 0.00001)\n",
    "    print('lam= ' + str(lam))\n",
    "    MSE(globalAverage_update, userAverage_update, businessAverage_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Because when lam=6.6, MSE is minimized. So we choose lam=6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "businessRatings = defaultdict(list)\n",
    "for l in valid_data:\n",
    "  user,business = l['reviewerID'],l['itemID']\n",
    "  allRatings.append(l['rating'])\n",
    "  userRatings[user].append(l['rating'])\n",
    "  businessRatings[business].append(l['rating'])\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "userAverage = {}\n",
    "businessAverage = {}\n",
    "for u in userRatings:\n",
    "  userAverage[u] = sum(userRatings[u]) / len(userRatings[u])\n",
    "for u in businessRatings:\n",
    "  businessAverage[u] = sum(businessRatings[u]) / len(businessRatings[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate1(globalAverage, userAverage, businessAverage, lam = 1, \\\n",
    "            threshold = 0.00001):\n",
    "    switch = 0\n",
    "    prev_globalAverage = globalAverage\n",
    "    prev_userAverage = userAverage\n",
    "    prev_businessAverage = businessAverage\n",
    "    while switch == 0:\n",
    "        globalAverage = 0\n",
    "        for l in valid_data:\n",
    "            user,business = l['reviewerID'],l['itemID']\n",
    "            globalAverage += (l[\"rating\"] - prev_userAverage[user] - \\\n",
    "                              prev_businessAverage[business])\n",
    "        globalAverage /= len(valid_data)\n",
    "        \n",
    "        nbusiness = defaultdict(int)\n",
    "        for user in userAverage:\n",
    "            userAverage[user] = 0\n",
    "        for l in valid_data:\n",
    "            user,business = l['reviewerID'],l['itemID']\n",
    "            nbusiness[user] += 1\n",
    "            userAverage[user] += (l[\"rating\"] - globalAverage - \\\n",
    "                                  prev_businessAverage[business])\n",
    "        for user in userAverage:\n",
    "            userAverage[user] /= (lam + nbusiness[user])\n",
    "        \n",
    "        difference_user = 0\n",
    "        for i in userAverage:\n",
    "            difference_user += abs(userAverage[i] - prev_userAverage[i])\n",
    "            \n",
    "        nuser = defaultdict(int)\n",
    "        for business in businessAverage:\n",
    "            businessAverage[business] = 0\n",
    "        for l in valid_data:\n",
    "            user,business = l['reviewerID'],l['itemID']\n",
    "            nuser[business] += 1\n",
    "            businessAverage[business] += (l[\"rating\"] - globalAverage - \\\n",
    "                                          userAverage[user])\n",
    "        for business in businessAverage:\n",
    "            businessAverage[business] /= (lam + nuser[business])\n",
    "        \n",
    "        difference_bus = 0\n",
    "        for i in businessAverage:\n",
    "            difference_bus += abs(businessAverage[i] - prev_businessAverage[i])        \n",
    "        \n",
    "        if abs(globalAverage - prev_globalAverage) < threshold and \\\n",
    "        difference_user < threshold and \\\n",
    "        difference_bus < threshold:\n",
    "            switch = 1\n",
    "        else:\n",
    "            prev_globalAverage = globalAverage\n",
    "            prev_userAverage = userAverage\n",
    "            prev_businessAverage = businessAverage\n",
    "    return globalAverage, userAverage, businessAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalAverage_update, userAverage_update, businessAverage_update = iterate(\\\n",
    "    globalAverage, userAverage, businessAverage, lam = 6.95, threshold = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "userlist = []\n",
    "businesslist = []\n",
    "for i in userAverage_update:\n",
    "    userlist.append(i)\n",
    "for j in businessAverage_update:\n",
    "    businesslist.append(j)\n",
    "predictions = open(\"assignment1/predictions_Rating.csv\", 'w')\n",
    "for l in open(\"assignment1/pairs_Rating.txt\"):\n",
    "    if l.startswith(\"reviewerID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')    \n",
    "    if (u in userlist) and (i in businesslist):\n",
    "        rating=globalAverage_update+userAverage_update[u]+businessAverage_update[i]\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "    elif (u in userlist) and (i not in businesslist):\n",
    "        rating=globalAverage_update+userAverage_update[u]\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "    elif (u not in userlist) and (i in businesslist):\n",
    "        rating=globalAverage_update+businessAverage_update[i]\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "    else:\n",
    "        rating=globalAverage_update\n",
    "        predictions.write(u + '-' + i + \",\"+str(rating)+\"\\n\")\n",
    "predictions.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
